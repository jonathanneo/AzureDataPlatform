{"cells":[{"cell_type":"code","source":["%run \"../Util/Util Functions\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a412d3b4-cd4d-4ee2-a014-af042a31c3fa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml.feature import MinMaxScaler\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import DoubleType\n\nimport random\n\nclass ClenseNumeric:\n  \"\"\"\n  Methods for cleaning and validating dataframe columns of numeric type.\n  \n  Attributes\n  ----------\n  ErrorValue : float\n    Value to return on error of user defined function\n  \n  Methods\n  -------\n  \n  \"\"\"\n  \n  ErrorValue = \"Failed Numeric Cleansing\"\n  \n  def clnMinMaxNormalise(df, columns: list, ErrorAction: str, ErrorValue, ErrorReplaceValue=None):\n    \"\"\"\n    Applies Min Max Normalisation to all values in a column for each column listed in the dataframe.\n    \n    Parameters\n    ----------\n    df : DataFrame\n    columns : list\n      List of string columns to normalise\n    ErrorAction : str {'ContinueAndNullValue', 'ContinueAndDropRow', ContinueAndReplaceValue, 'Stop'}\n    ErrorValue\n    ErrorReplaceValue : str\n    \n    Returns\n    -------\n    df_cleaned : DataFrame\n      Cleaned Spark DataFrame\n    df_errors : DataFrame\n      DataFrame containing records where cleaning failed\n    \"\"\"\n    \n    # UDF for converting column type from vector to double type\n    unlist = udf(lambda x: round(float(list(x)[0]),3), DoubleType())\n\n    # Iterating over columns to be scaled\n    for c_name in columns:\n      # VectorAssembler Transformation - Converting column to vector type\n      assembler = VectorAssembler(inputCols=[c_name],outputCol=c_name+\"_Vect\")\n      # MinMaxScaler Transformation\n      scaler = MinMaxScaler(inputCol=c_name+\"_Vect\", outputCol=c_name+\"_Scaled\")\n      # Pipeline of VectorAssembler and MinMaxScaler\n      pipeline = Pipeline(stages=[assembler, scaler])\n      # Fitting pipeline on dataframe\n      df = pipeline.fit(df).transform(df).withColumn(c_name+\"_Scaled\", unlist(c_name+\"_Scaled\")).drop(c_name+\"_Vect\")\n    \n    # blank df for error handling\n    df_blank = spark.createDataFrame([], df.schema)\n    \n    return df, df_blank"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"289098dd-d5a2-4013-905f-aab33ab47e61"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Numeric","dashboards":[],"language":"python","widgets":{},"notebookOrigID":489289456851650}},"nbformat":4,"nbformat_minor":0}
